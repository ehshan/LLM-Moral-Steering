{"cells":[{"cell_type":"markdown","source":["# Testing Model Access via Huggingface"],"metadata":{"id":"KTcCFUqCeRQL"}},{"cell_type":"markdown","source":["## Install"],"metadata":{"id":"XpiXrcDnhX9A"}},{"cell_type":"code","source":["# transformers library needed to load tokenizers\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAM77TYvMAc5","executionInfo":{"status":"ok","timestamp":1761259310304,"user_tz":-60,"elapsed":5634,"user":{"displayName":"ehshan veerabangsa","userId":"04373256007833622837"}},"outputId":"14bd6ed8-d8b7-4bf9-82ed-6f0b746f3323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"]}]},{"cell_type":"markdown","source":["## Environment Setup"],"metadata":{"id":"orRu9v2afBFV"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","from google.colab import drive, userdata\n","import os\n","\n","# Mount Google Drive\n","print(\"Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"Drive mounted successfully.\")\n","\n","# Retrieve workpace path\n","WORKING_DIR = userdata.get('moral_path')\n","# change working directory\n","os.chdir(WORKING_DIR)\n","# check the current directory\n","!pwd\n","\n","# Get the token from Colab's secrets manager\n","try:\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","    if HF_TOKEN is None:\n","        raise ValueError(\"HF_TOKEN not found in Colab secrets.\")\n","\n","    # Set the token as an environment variable for Hugging Face Hub\n","    os.environ['HF_TOKEN'] = HF_TOKEN\n","    print(\"Successfully retrieved HF_TOKEN from Colab secrets.\")\n","\n","except Exception as e:\n","    print(f\"Error retrieving HF_TOKEN: {e}\")\n","    print(\"Check secrets tab\")."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yC-bL_ZZMAZZ","executionInfo":{"status":"ok","timestamp":1761261592708,"user_tz":-60,"elapsed":29233,"user":{"displayName":"ehshan veerabangsa","userId":"04373256007833622837"}},"outputId":"15dd5b11-1697-4e6e-93ab-d08501ade92e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Mounted at /content/drive\n","Drive mounted successfully.\n","/content/drive/My Drive/_PhD/Moral-Reasoning/Experiments/Data\n","Successfully retrieved HF_TOKEN from Colab secrets.\n"]}]},{"cell_type":"markdown","source":["## Check models load"],"metadata":{"id":"bMP4usNtMdY1"}},{"cell_type":"code","source":["# The three models we want to check access for\n","MODELS_TO_TEST = [\n","    \"meta-llama/Meta-Llama-3.1-8B-Instruct\", # Llama\n","    \"mistralai/Mistral-7B-Instruct-v0.3\", # Mistral\n","    \"google/gemma-7b-it\" # Gemma\n","]\n","\n","print(\"--- Starting Tokenizer Access Test ---\")\n","print(f\"Using HF_TOKEN starting with: {HF_TOKEN[:5]}...\")\n","\n","# Loop through each model and try to load its tokenizer\n","for model_id in MODELS_TO_TEST:\n","    print(\"\\n\" + \"=\"*30)\n","    print(f\"Attempting to load tokenizer for: {model_id}\")\n","\n","    try:\n","        # Process:\n","        # 1. Use HF_TOKEN to authenticate.\n","        # 2. Check if accepted the model's license/terms.\n","        # 3. Download the tokenizer files.\n","        tokenizer = AutoTokenizer.from_pretrained(model_id)\n","\n","        print(f\"SUCCESS: Tokenizer for {model_id} loaded successfully.\")\n","\n","    except OSError as e:\n","        # This specific error (OSError for auth failures)\n","        if \"Gated\" in str(e) or \"access\" in str(e):\n","            print(f\"FAILURE (Access Denied): Access to model not granted.\")\n","            print(f\"Model Card: https://huggingface.co/{model_id}\")\n","        else:\n","            print(f\"FAILURE (Error): An unexpected error occurred: {e}\")\n","    except Exception as e:\n","        print(f\"FAILURE (Unknown Error): {e}\")\n","\n","print(\"\\n\" + \"=\"*30)\n","print(\"--- Test Complete ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7YFUw1cMAXU","executionInfo":{"status":"ok","timestamp":1761261604855,"user_tz":-60,"elapsed":6062,"user":{"displayName":"ehshan veerabangsa","userId":"04373256007833622837"}},"outputId":"9bf8ec57-a8fd-4d67-cf89-d3676f4eb604"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Tokenizer Access Test ---\n","Using HF_TOKEN starting with: hf_OU...\n","\n","==============================\n","Attempting to load tokenizer for: meta-llama/Meta-Llama-3.1-8B-Instruct\n","✅ SUCCESS: Tokenizer for meta-llama/Meta-Llama-3.1-8B-Instruct loaded successfully.\n","\n","==============================\n","Attempting to load tokenizer for: mistralai/Mistral-7B-Instruct-v0.3\n","✅ SUCCESS: Tokenizer for mistralai/Mistral-7B-Instruct-v0.3 loaded successfully.\n","\n","==============================\n","Attempting to load tokenizer for: google/gemma-7b-it\n","✅ SUCCESS: Tokenizer for google/gemma-7b-it loaded successfully.\n","\n","==============================\n","--- Test Complete ---\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1F-sv1ba1pVNaJhjc3ZjUlrKOFQHxvOwd","authorship_tag":"ABX9TyOrasdem0NI8OmtUmLouSDd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}